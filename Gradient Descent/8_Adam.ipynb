{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam stands for adaptive moment estimation, it combines the benefits of Momentum-based Gradient Descent, Adagrad, and RMSprop the learning rate is adaptively adjusted for each parameter based on the moving average of the gradient and the squared gradient, which allows for faster convergence and better performance on non-convex optimization problems. It keeps track of two exponentially decaying averages the first-moment estimate, which is the exponentially decaying average of past gradients, and the second-moment estimate, which is the exponentially decaying average of past squared gradients. The first-moment estimate is used to calculate the momentum, and the second-moment estimate is used to scale the learning rate for each parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimizer inherits the strengths or the positive attributes of the above two methods and builds upon them to give a more optimized gradient descent. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Momentum :  \n",
    "Wt+1 = Wt - alpha * mt\n",
    "here instead of grad, we are using mt, what is it ?  \n",
    "mt = Beta * mt-1 + (1-Beta) * Grad  \n",
    "\n",
    "\n",
    "From RMS :  \n",
    "Here \n",
    "wt+1 =wt - [ɑt / sqrt(vt + e) ] * grad    \n",
    "here the LR is adjusted with vt  \n",
    "vt = Beta* v(t-1) + ( 1 - Beta) * Grad ** 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since mt and vt have both initialized as 0 (based on the above methods), it is observed that they gain a tendency to be ‘biased towards 0’ as both β1 & β2 ≈ 1. This Optimizer fixes this problem by computing ‘bias-corrected’ mt and vt. This is also done to control the weights while reaching the global minimum to prevent high oscillations when near it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively, we are adapting to the gradient descent after every iteration so that it remains controlled and unbiased throughout the process, hence the name Adam. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For zero corection :  \n",
    "\n",
    "mt_hat = mt / 1-Beta1t  \n",
    "vt_hat = vt / 1-Beta2t  \n",
    "\n",
    "Weiht Update :  \n",
    "w(t+1) = wt + [alpha / sqrt(vt_hat + e) ]* mt_hat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createModel(input_shape): \n",
    "    X_input = tf.keras.layers.Input(input_shape) \n",
    "    X = tf.keras.layers.Dense(10, 'relu')(X_input) \n",
    "    X_output = tf.keras.layers.Dense(2, 'softmax')(X) \n",
    "    model = tf.keras.Model(inputs=X_input, outputs=X_output) \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = createModel((10, 10)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)          │            <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m2\u001b[0m)          │            \u001b[38;5;34m22\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> (528.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m132\u001b[0m (528.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Layer Weights\n",
      "\n",
      "Weight for Layer 1: \n",
      "[[ 0.296719    0.12479973 -0.03654027 -0.01508188 -0.5403854  -0.52189714\n",
      "  -0.33469433 -0.01031756  0.00877666 -0.11324003]\n",
      " [-0.364394   -0.28073815 -0.05136335 -0.23935804 -0.15700006 -0.19092757\n",
      "   0.5272951   0.27842534  0.03753638  0.02051485]\n",
      " [ 0.27769494 -0.03429574  0.20139593 -0.09179577 -0.01420242  0.08377004\n",
      "  -0.00702471 -0.04625934  0.321429    0.23440176]\n",
      " [ 0.53380704 -0.08840534  0.09720039  0.33096737 -0.14456922  0.12651277\n",
      "  -0.19154158 -0.07113087 -0.09058133  0.22444093]\n",
      " [ 0.1007576   0.08510673 -0.15253386  0.09979451  0.3576933   0.24536377\n",
      "   0.18271935 -0.1307903   0.21833521 -0.4238966 ]\n",
      " [ 0.3218513  -0.35115626  0.2664861  -0.46591854 -0.27767992 -0.4476878\n",
      "   0.35598958 -0.4031749  -0.25424656 -0.41667828]\n",
      " [ 0.03161305 -0.08007896  0.1780827  -0.20949185 -0.4138363   0.01499754\n",
      "   0.47309482  0.19412655  0.18258017 -0.12325215]\n",
      " [-0.08922386  0.26008135 -0.48908237  0.29042888 -0.33507407  0.21547616\n",
      "  -0.451172   -0.19824463 -0.1628159  -0.49050474]\n",
      " [-0.32650048  0.4577092  -0.48076737  0.4237286   0.42112726 -0.26737255\n",
      "   0.20094097  0.2836457  -0.4333992   0.04815769]\n",
      " [-0.5339348   0.27519995  0.05820364 -0.37113702  0.43620998 -0.35961807\n",
      "   0.36936224  0.33121336  0.38963616 -0.39013106]]\n",
      "\n",
      "Weight for Layer 2: \n",
      "[[ 0.07204247  0.3807103 ]\n",
      " [ 0.11318213  0.5971404 ]\n",
      " [ 0.277012   -0.6108059 ]\n",
      " [ 0.61623794  0.16723162]\n",
      " [ 0.10234147 -0.67529553]\n",
      " [ 0.04432464 -0.5768548 ]\n",
      " [ 0.34841126  0.6576038 ]\n",
      " [ 0.10273379 -0.32170016]\n",
      " [-0.21213049 -0.6809489 ]\n",
      " [ 0.18628621  0.49670476]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Initial Layer Weights') \n",
    "print() \n",
    "for i in range(1, len(model.layers)): \n",
    "    print('Weight for Layer '+str(i)+': ') \n",
    "    print(model.layers[i].get_weights()[0]) \n",
    "    print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(5) \n",
    "X = tf.random.normal((2, 10, 10)) \n",
    "Y = tf.random.normal((2, 10, 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'adam', 'learning_rate': 0.0010000000474974513, 'weight_decay': None, 'clipnorm': None, 'global_clipnorm': None, 'clipvalue': None, 'use_ema': False, 'ema_momentum': 0.99, 'ema_overwrite_frequency': None, 'loss_scale_factor': None, 'gradient_accumulation_steps': None, 'beta_1': 0.9, 'beta_2': 0.999, 'epsilon': 1e-07, 'amsgrad': False}\n"
     ]
    }
   ],
   "source": [
    "print(model.optimizer.get_config()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 668ms/step - accuracy: 0.3000 - loss: 0.1425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1db4cb2bb80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Layer Weights\n",
      "\n",
      "Weight for Layer 1: \n",
      "[[ 0.29771885  0.12379976 -0.03754019 -0.01608174 -0.53938544 -0.52089727\n",
      "  -0.33569428 -0.00931771  0.00977662 -0.11423938]\n",
      " [-0.3633946  -0.2817381  -0.0523631  -0.240358   -0.15799971 -0.18992762\n",
      "   0.5262951   0.2774269   0.03853633  0.01951489]\n",
      " [ 0.2766951  -0.03529542  0.20239589 -0.09079581 -0.01320247  0.0847697\n",
      "  -0.00802468 -0.0452594   0.32242894  0.23340182]\n",
      " [ 0.5348069  -0.08940531  0.09620042  0.32996738 -0.14356926  0.12751272\n",
      "  -0.1905416  -0.07213072 -0.0915813   0.22544073]\n",
      " [ 0.09975782  0.08610667 -0.15353383  0.10079448  0.35669342  0.24436384\n",
      "   0.18371932 -0.13179024  0.21933514 -0.42289662]\n",
      " [ 0.3208514  -0.3521562   0.26748607 -0.46491855 -0.27667993 -0.44668785\n",
      "   0.3549896  -0.40217498 -0.2532466  -0.4176781 ]\n",
      " [ 0.03261162 -0.07907899  0.17908248 -0.20849188 -0.4148363   0.01399759\n",
      "   0.47209492  0.19512624  0.18358007 -0.12225237]\n",
      " [-0.08822399  0.25908142 -0.49008226  0.29142815 -0.3340741   0.21447623\n",
      "  -0.45217195 -0.19724476 -0.16181597 -0.4895048 ]\n",
      " [-0.3275003   0.45870915 -0.47976738  0.42272863  0.4201273  -0.26637268\n",
      "   0.20194092  0.28264576 -0.43439913  0.04715773]\n",
      " [-0.53493434  0.27419996  0.0592036  -0.3721369   0.43720996 -0.35861808\n",
      "   0.36836225  0.33221298  0.39063612 -0.3911309 ]]\n",
      "\n",
      "Weight for Layer 2: \n",
      "[[ 0.07104248  0.38171023]\n",
      " [ 0.11218215  0.5981403 ]\n",
      " [ 0.276012   -0.61180586]\n",
      " [ 0.61523795  0.16823159]\n",
      " [ 0.10134149 -0.6742956 ]\n",
      " [ 0.04332466 -0.57585484]\n",
      " [ 0.34741127  0.6566039 ]\n",
      " [ 0.1017338  -0.32270005]\n",
      " [-0.21313047 -0.68194884]\n",
      " [ 0.18528622  0.4957048 ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Final Layer Weights') \n",
    "print() \n",
    "for i in range(1, len(model.layers)): \n",
    "    print('Weight for Layer '+str(i)+': ') \n",
    "    print(model.layers[i].get_weights()[0]) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
